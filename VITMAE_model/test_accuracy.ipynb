{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTMAEConfig\n",
    "from transformers import ViTForImageClassification\n",
    "from dataloader import test_square_xrd_classification_dataloader\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './YOUR TRAINED MODEL PATH HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForImageClassification.from_pretrained(path )\n",
    "model.config.num_labels\n",
    "model= nn.DataParallel(model) #only have this if you run the model on data parallel device\n",
    "model.load_state_dict(torch.load(\"./TRAINED VITMAE MODEL.pth\",map_location='cpu')) #change accordingly to your target device 'cpu' or 'cuda'\n",
    "torch.save(model.module.state_dict(), \"./test_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './SAVE PATH FOR YOUR VITCLASSIFICATION'\n",
    "model = ViTForImageClassification.from_pretrained(path)\n",
    "model.load_state_dict(torch.load(\"./test_model.pth\",map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_sum = 0\n",
    "total_len = 0\n",
    "\n",
    "for idx, data in enumerate(test_square_xrd_classification_dataloader):\n",
    "        classification = data[:, :, -1, 0]-1\n",
    "        classification_gpu = torch.from_numpy(classification.long().numpy()[:,0])\n",
    "        data = data[:, :, :-1, :]\n",
    "        output = model(data)\n",
    "        \n",
    "        output = np.argmax(output.logits.detach().numpy(), axis=1)\n",
    "        cache = output == classification.numpy().astype(int).squeeze()\n",
    "        total_sum += sum(cache)\n",
    "        total_len += len(cache)\n",
    "        if idx%20 ==0:\n",
    "                print(f' batch {idx}, accuracy = {total_sum/total_len}')\n",
    "print(f'accuracy = {total_sum/total_len}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('perceiver-io')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f924eb19180ecde0db14e682b5804ad4e24b2fe50b99adcf7a85c55a74bd824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
